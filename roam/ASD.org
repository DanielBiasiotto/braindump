#+TITLE: Algoritmi e Strutture Dati
#+TEACHER: Andras Horvath(horvathATdi.unito.it)
[[file:#universita.org][#universita]]
Esame
- scritto
- discussione laboratorio

Libro
- Introduzione agli algoritmi e strutture dati

* Problemi e Algoritmi

** Problemi Computazionali
Collezione di domande (istanze-ingressi) per cui sia stabilito un criterio astratto per riconoscere le risposte (uscite) corrette
- Es
  - Massimo comune divisore
  - moltiplicazione fra due interi
  - fattorizzazione
  - ordinamento
  - percorso ottimo in un grafo

Un Problema e' una _Relazione Binaria_
$R = {(istanza,risposta) : istanza, risposta soddisfano...}$
Il _dominio_ della relazione e' l'insieme delle domande possibili
R e' _univoca_ se ogni istanza ammette una sola risposta

** Algoritmi
Metodo meccanico per risolvere un Problema Computazionale
- Procedura
  + produce un output da qualsiasi input
- Algoritmo
  + procedura che termina per ogni ingressa ammissibile

Un algoritmo e' detto deterministico se sulla stesso input fornisce sempre lo stesso output
- ad ogni algoritmo deterministico possiamo associare una finzione input-output

Un algoritmo risolve R, ossia e' corretto rispetto ad R, se la sua funzione A associa una risposta ad ogni istanza di R

Un programma imlementa piu' algoritmi, inoltre implementa opportune strutture dati

*** Peak Finding
Input: vettore A[0...n-1] interi positivi
Output: un intero 0<= p <n t.c. A[p-1]<=A[p]>=A[p+1] dove A[-1]=A[n]=-inf

Peak(A)
for(i=0;i<length(A);i++)
    if(A[i]>=A[i-1] && A[i]>=A[i+1])
        return i
end for

**** Left Peak Finding
Nel caso migliore p=0 e' un picco
Nel caso peggiore p=n-1 confronti
**** Max Peak Finding
MAX-PEAK(A)
r = 0
i = 1
while(i<n-1)
    if A[i] > A[r]
        r <- i
    i <- i+1
end while
return r

Fa sempre lo stesso numero di confronti, sempre n-1

**** Analisi
Teorema picco
Si trovano segmenti sempre piu' corti su cui vale il teorema a partire da un q centrale.

**** Divide et Impera
PEAK-DI
p<-(i+j)/2
if A[p-1]<=A[p]>=A[p+1] then
    return p
else
    if A[p-1]>A[p] then
        return PEAK-DI(A,i,p-1)
    else
        return PEAK-DI(A,p+1,j)
    endif
endif

PEAK-FIND-DI(A,n)
return PEAK-DI(A,0,n-1)

- T(n)=
  - 1;        n=1
  - T(n/2)+1; n>1
$T(n)=T(\frac{n}{2^k})+k$ per $1\le k \le \log_{2}n$
$T(n)=1+\log_{2}n$
** Insolubilita' e Intrattabilita'
non tutti i problemi hanno una soluzione algoritmica (problema della terminazione)

intrattabile e' un problema che ha una soluzione algoritmica ma lo sforzo computazionale e' troppo grande

** Correttezza
Totale e Parziale

Specifica
- Precondizioni
- Postcondizioni
  - criterio che stabilisce come deve essere fatto l'output
**** Ricorsione
Un problema si presta alla ricorsione quando la ricorsione con un certo input ha una relazione semplice con la soluzione del problema con uno o piu' input diminuiti
#+begin_example
HANOI(n,solgente,destinazione,appoggio)
PRE:
- n>0
- base degli n dischi in alto ha diametro piu' piccolo del disco piu' in alto sia di destinazione che di appoggio
POST:
- torre di n dischi piu' in alto su sorgente e' spostata su destinazione

if n-1 then
    sposta un disco da sorgente a destinazione
else
    HANOI(n-1, sorgente, appoggio, destinazione)
    sposta un disco da solgente a destinazione
    HANOI(n-1, appoggio, destinazione, sorgente)
endif
#+end_example
#+begin_example
DIV-REC(a,b)
- Pre: a ge 0, b > 0
- Post: q, r t.c. a eq bq + r AND 0 le r < b
if a < b then
    q,r <- 0,a
else
    q',r <- DIV-REC(a-b,b)
    q <- q'+1
end if
return q,r
#+end_example
***** Schema dell'induzione semplice
1. Caso base P(1)
2. Passo induttivo P(m+1), P(m) e' l'ipotesi induttiva
3. 1. e 2. implicano che $\forall n \ge 1, P(n)$
***** Schema dell'induzione completa
1. Caso base $$
2. Passo induttivo
3. Conclusione
**** Iterazione
Divisione Intera
#+begin_example
DIV_IT(a,b)
while r ge b do
    r <- r-b
    q <- q+1
end while
return r,q
#+end_example

Si utilizzano le _invarianti_ per la dimostrazione di correttezza
- sempre vera:
  + inizializzazione
  + mantenimento
    - vale prima del ciclo --> vale anche dopo il corpo del ciclo
Va scelto in modo che sia utile per la dimostrazione di correttezza

** Terminazione
T2 temporal prover
- la non terminazione puo' essere semplicemente causata da un errore logico
- non terminazione implicita nel problema
  + problema $3n+1$
    - _Congettura di Collatz_
E' difficile dimostrare la terminazione se i parametri non decrescono in tutti i casi
Spesso gli algoritmi diminuiscono la dimensione dei parametri, l'ampiezza dell'intervallo

** Problema del Ordinamento - Sorting
*** Ricerca dicotomica o binaria
- dimezza la dimensione del problema ad ogni passo
#+begin_example
BinSearch-Ric(x,A,i,j)
- Pre: A[i...j] ordinato
- Post: true se x appartiene A[i...j]
if i>j then
    return false
else
    m <- floor((i+j)/2)
    if x eq A[m] then
        return true
    else
        if x<A[m] then
            return BinSearch-Ric(x,A,i,m-1)
        else
            return BinSearch-Ric(x,A,m+1,j)
        end if
    end if
end if
#+end_example
Casi
- best: $1$
- worst: $log_2 n$
*** Insertion Sort
per ordinare A[1...n]
- la parte A[1...i-1] gia' ordinato
- si puo' inserire l'elemento A[i] nella parte ordinata tramite scambi
  - se A[i] > A[i-1] -> A[1...i] e' ordinato e ci si ferma; altrimenti si scambia A[i] con A[i-1]
  - se A[i-1] > A[i-2] -> A[1...i] e' ordinato; altrimenti si scambia A[i-1] e A[i-2]
  - ...
Si parte inserendo A[2] poi si prosegue fino a n
#+begin_example
Insertion-Sort(A)
for i<-2 to length(A) do
    j<-i
    while j>1 and A[j-1]>A[j] do
        scambia A[j-1] con A[j]
        j<-j-1
    end while
end for
return A
#+end_example
**** Terminazione
assicurata dalla limitatezza dei cicli *for* e *while*
**** Correttezza
2 cicli -> 2 invarianti
1. A[1...i-1] e' ordinato
   a. corretto se il ciclo interno e' corretto
2. A[1...j-1] e A[j...i] sono ordinati AND A[1...j-1] le A[j+1...i]
All'uscita dell'algoritmo abbiamo i uguale a n+1 che implica che tutto il vettore A[1...n] e' ordinato
**** Complessita'
dipende da n e dalla distribuzione all'interno del vettore
assegnamo un costo ad ogni riga dell'algoritmo e lo moltiplichiamo alle volte per cui e' eseguito
1. for     - n volte
2. <-      - n-1
3. while   - sum_{i}^{n}{t_i-1}
   a. 1 nel caso migliore
   b. i nel caso peggiore
4. scambio - sum_{i}^{n}{t_i-1}

*Worst*
an^2 + bn + c
Nel caso peggiore Insert-Sort ha complessita' temporale quadratica
*Best*
dn + e
Nel caso miglione Insert-Sort ha complessita' temporale lineare
*** Selection Sort
Assumiamo che la parte sx del vettore sia gia' ordinata e che contenga elementi maggiori-uguale di questa parte a dx
- cerchiamo l'elemento minimo della parte dx e lo spostiamo in ultima posizione a sx (diminuendo la dimensione del problema)
#+begin_example
Selection-Sort(A)
for i <- 1 to length(A)-1 do
    j <- i+1
    k <- i
    while j < length(A)+1 do
        if A[j] < A[k] do
            k <- j
        end if
        j <- j+1
    end while
    scambia A[i] e A[k]
end for
return A
#+end_example
**** Terminazione
Implicata dalla terminazione dei cicli
**** Correttezza
2 Invarianti
1. A[1...i-1] ordinato e A[i...n] > uguale a A[1...i-1]
2. A[k] < uguale a A[i...j-1]

**** Complessita'
Sia nel caso migliore che nel caso poggiore,
Complessita' temporale quadratica

*** Alberi di Decisione
le foglie dell'albero devono essere tutte le possibili pormutazioni degli elementi del vettore
- $n!$
- per costruire un albero con un numero tale di foglie sono necessari almeno $log_2 n!$ livelli
- Usando la formula di Stirling per approssimare $n!$
  + $n log_2 n$
Che cresce molto piu' lentamente di una funzione quadratica
- cio' implica che esistano algoritmi molto piu' efficienti di quelli quadratici visti

** Complessita' di un algoritmo
Risorse utilizzate dall'algoritmo
- tempo
- spazio
- hardware
  + sempre piu' importante con piu' core e thread di esecuzione
Noi trattiamo la complessita' temporale
- per stimare la grandezza massima dell'ingresso(input) di un esecuzione ragionevole
- per confrontare l'efficienza di piu' algoritmi

Il tempo di calcolo e' una funzione rispetto all'input
Approcci, gli approcci differiscono solo di una costante moltiplicativa sotto certe condizioni:
- secondi di esecuzioni
- numero di operazioni elementari
- numero di volte una specifica operazione viene eseguita
  + piu' semplice

Una volta stabiliti i numeri di esecuzioni si passa all'analisi del caso migliore e del caso peggiore, si riconducono a polinomi

La *dimensione dell'ingresso* e' una misura della sua rappresentazione
- $|m| log_2 (m)+1$
- $|A[0...n-1]| nc$
  + $c$ numero bit del generico elemento di $A$
    - $c 1$ perche' le costanti moltiplicative non contano dal punto di vista dell'analisi asintotica

Fissato la dimensione esistano algoritmi per cui $T$ puo' cambiare rispetto alla forma dell'input
Distinguiamo i casi: migliore e peggiore
 - $T_{peggiore}(n) max{T()x}: |x|n$
 - $T_{migliore}(n) min{T()x}: |x|n$
Dobbiamo confrontare tra loro funzioni che hanno infiniti valori
- si trascura il numero finito di casi, conviene scegliere la funzione che cresce piu' lentamente all'infinito
  + se non ci interessano questi casi, se abbiamo informazioni in piu' allora vanno analizzati anche questi casi
Quanto contano le costanti?
- con un computer molto piu' veloce la dimensione massima trattabile cambia in maniera trascurabile
- la funzione che cresce meno velocemente e' comunque piu' importante di una costante moltiplicativa per il calcolo della complessita'
- inoltre la stima delle costanti e' molto difficile nella pratica

*** Minimo
$cn + d le T(n) le an+b$
- contenuto tra funzioni lineari
  + al piu' lineare
