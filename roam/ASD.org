#+TITLE: Algoritmi e Strutture Dati
#+TEACHER: Andras Horvath(horvath@di.unito.it)
[[file:#universita.org][#universita]]
Esame
- scritto
- discussione laboratorio

Libro
- Introduzione agli algoritmi e strutture dati

* Problemi e Algoritmi

** Problemi Computazionali
Collezione di domande (istanze-ingressi) per cui sia stabilito un criterio astratto per riconoscere le risposte (uscite) corrette
- Es
  - Massimo comune divisore
  - moltiplicazione fra due interi
  - fattorizzazione
  - ordinamento
  - percorso ottimo in un grafo

Un Problema e' una _Relazione Binaria_
$R = {(istanza,risposta) : istanza, risposta soddisfano...}$
Il _dominio_ della relazione e' l'insieme delle domande possibili
R e' _univoca_ se ogni istanza ammette una sola risposta

** Algoritmi
Metodo meccanico per risolvere un Problema Computazionale
- Procedura
  + produce un output da qualsiasi input
- Algoritmo
  + procedura che termina per ogni ingressa ammissibile

Un algoritmo e' detto deterministico se sulla stesso input fornisce sempre lo stesso output
- ad ogni algoritmo deterministico possiamo associare una finzione input-output

Un algoritmo risolve R, ossia e' corretto rispetto ad R, se la sua funzione A associa una risposta ad ogni istanza di R

Un programma imlementa piu' algoritmi, inoltre implementa opportune strutture dati

*** Peak Finding
Input: vettore A[0...n-1] interi positivi
Output: un intero 0<= p <n t.c. A[p-1]<=A[p]>=A[p+1] dove A[-1]=A[n]=-inf

Peak(A)
for(i=0;i<length(A);i++)
    if(A[i]>=A[i-1] && A[i]>=A[i+1])
        return i
end for

**** Left Peak Finding
Nel caso migliore p=0 e' un picco
Nel caso peggiore p=n-1 confronti
**** Max Peak Finding
MAX-PEAK(A)
r = 0
i = 1
while(i<n-1)
    if A[i] > A[r]
        r <- i
    i <- i+1
end while
return r

Fa sempre lo stesso numero di confronti, sempre n-1

**** Analisi
Teorema picco
Si trovano segmenti sempre piu' corti su cui vale il teorema a partire da un q centrale.

**** Divide et Impera
PEAK-DI
p<-(i+j)/2
if A[p-1]<=A[p]>=A[p+1] then
    return p
else
    if A[p-1]>A[p] then
        return PEAK-DI(A,i,p-1)
    else
        return PEAK-DI(A,p+1,j)
    endif
endif

PEAK-FIND-DI(A,n)
return PEAK-DI(A,0,n-1)

- T(n)=
  - 1;        n=1
  - T(n/2)+1; n>1
$T(n)=T(\frac{n}{2^k})+k$ per $1\le k \le \log_{2}n$
$T(n)=1+\log_{2}n$
** Insolubilita' e Intrattabilita'
non tutti i problemi hanno una soluzione algoritmica (problema della terminazione)

intrattabile e' un problema che ha una soluzione algoritmica ma lo sforzo computazionale e' troppo grande

** Correttezza
Totale e Parziale

Specifica
- Precondizioni
- Postcondizioni
  - criterio che stabilisce come deve essere fatto l'output
**** Ricorsione
Un problema si presta alla ricorsione quando la ricorsione con un certo input ha una relazione semplice con la soluzione del problema con uno o piu' input diminuiti
#+begin_example
HANOI(n,solgente,destinazione,appoggio)
PRE:
- n>0
- base degli n dischi in alto ha diametro piu' piccolo del disco piu' in alto sia di destinazione che di appoggio
POST:
- torre di n dischi piu' in alto su sorgente e' spostata su destinazione

if n-1 then
    sposta un disco da sorgente a destinazione
else
    HANOI(n-1, sorgente, appoggio, destinazione)
    sposta un disco da solgente a destinazione
    HANOI(n-1, appoggio, destinazione, sorgente)
endif
#+end_example
#+begin_example
DIV-REC(a,b)
- Pre: a ge 0, b > 0
- Post: q, r t.c. a eq bq + r AND 0 le r < b
if a < b then
    q,r <- 0,a
else
    q',r <- DIV-REC(a-b,b)
    q <- q'+1
end if
return q,r
#+end_example
***** Schema dell'induzione semplice
1. Caso base P(1)
2. Passo induttivo P(m+1), P(m) e' l'ipotesi induttiva
3. 1. e 2. implicano che $\forall n \ge 1, P(n)$
***** Schema dell'induzione completa
1. Caso base $$
2. Passo induttivo
3. Conclusione
**** Iterazione
Divisione Intera
#+begin_example
DIV_IT(a,b)
while r ge b do
    r <- r-b
    q <- q+1
end while
return r,q
#+end_example

Si utilizzano le _invarianti_ per la dimostrazione di correttezza
- sempre vera:
  + inizializzazione
  + mantenimento
    - vale prima del ciclo --> vale anche dopo il corpo del ciclo
Va scelto in modo che sia utile per la dimostrazione di correttezza

** Terminazione
T2 temporal prover
- la non terminazione puo' essere semplicemente causata da un errore logico
- non terminazione implicita nel problema
  + problema $3n+1$
    - _Congettura di Collatz_
E' difficile dimostrare la terminazione se i parametri non decrescono in tutti i casi
Spesso gli algoritmi diminuiscono la dimensione dei parametri, l'ampiezza dell'intervallo

** Problema del Ordinamento - Sorting
*** Ricerca dicotomica o binaria
- dimezza la dimensione del problema ad ogni passo
#+begin_example
BinSearch-Ric(x,A,i,j)
- Pre: A[i...j] ordinato
- Post: true se x appartiene A[i...j]
if i>j then
    return false
else
    m <- floor((i+j)/2)
    if x eq A[m] then
        return true
    else
        if x<A[m] then
            return BinSearch-Ric(x,A,i,m-1)
        else
            return BinSearch-Ric(x,A,m+1,j)
        end if
    end if
end if
#+end_example
Casi
- best: $1$
- worst: $log_2 n$
*** Insertion Sort
per ordinare A[1...n]
- la parte A[1...i-1] gia' ordinato
- si puo' inserire l'elemento A[i] nella parte ordinata tramite scambi
  - se A[i] > A[i-1] -> A[1...i] e' ordinato e ci si ferma; altrimenti si scambia A[i] con A[i-1]
  - se A[i-1] > A[i-2] -> A[1...i] e' ordinato; altrimenti si scambia A[i-1] e A[i-2]
  - ...
Si parte inserendo A[2] poi si prosegue fino a n
#+begin_example
Insertion-Sort(A)
for i<-2 to length(A) do
    j<-i
    while j>1 and A[j-1]>A[j] do
        scambia A[j-1] con A[j]
        j<-j-1
    end while
end for
return A
#+end_example
**** Terminazione
assicurata dalla limitatezza dei cicli *for* e *while*
**** Correttezza
2 cicli -> 2 invarianti
1. A[1...i-1] e' ordinato
   a. corretto se il ciclo interno e' corretto
2. A[1...j-1] e A[j...i] sono ordinati AND A[1...j-1] le A[j+1...i]
All'uscita dell'algoritmo abbiamo i uguale a n+1 che implica che tutto il vettore A[1...n] e' ordinato
**** Complessita'
dipende da n e dalla distribuzione all'interno del vettore
assegnamo un costo ad ogni riga dell'algoritmo e lo moltiplichiamo alle volte per cui e' eseguito
1. for     - n volte
2. <-      - n-1
3. while   - sum_{i}^{n}{t_i-1}
   a. 1 nel caso migliore
   b. i nel caso peggiore
4. scambio - sum_{i}^{n}{t_i-1}

*Worst*
an^2 + bn + c
Nel caso peggiore Insert-Sort ha complessita' temporale quadratica
*Best*
dn + e
Nel caso miglione Insert-Sort ha complessita' temporale lineare
*** Selection Sort
Assumiamo che la parte sx del vettore sia gia' ordinata e che contenga elementi maggiori-uguale di questa parte a dx
- cerchiamo l'elemento minimo della parte dx e lo spostiamo in ultima posizione a sx (diminuendo la dimensione del problema)
#+begin_example
Selection-Sort(A)
for i <- 1 to length(A)-1 do
    j <- i+1
    k <- i
    while j < length(A)+1 do
        if A[j] < A[k] do
            k <- j
        end if
        j <- j+1
    end while
    scambia A[i] e A[k]
end for
return A
#+end_example
**** Terminazione
Implicata dalla terminazione dei cicli
**** Correttezza
2 Invarianti
1. A[1...i-1] ordinato e A[i...n] > uguale a A[1...i-1]
2. A[k] < uguale a A[i...j-1]

**** Complessita'
Sia nel caso migliore che nel caso poggiore,
Complessita' temporale quadratica

*** Alberi di Decisione
le foglie dell'albero devono essere tutte le possibili pormutazioni degli elementi del vettore
- $n!$
- per costruire un albero con un numero tale di foglie sono necessari almeno $log_2 n!$ livelli
- Usando la formula di Stirling per approssimare $n!$
  + $n log_2 n$
Che cresce molto piu' lentamente di una funzione quadratica
- cio' implica che esistano algoritmi molto piu' efficienti di quelli quadratici visti

** Complessita' di un algoritmo
Risorse utilizzate dall'algoritmo
- tempo
- spazio
- hardware
  + sempre piu' importante con piu' core e thread di esecuzione
Noi trattiamo la complessita' temporale
- per stimare la grandezza massima dell'ingresso(input) di un esecuzione ragionevole
- per confrontare l'efficienza di piu' algoritmi

Il tempo di calcolo e' una funzione rispetto all'input
Approcci, gli approcci differiscono solo di una costante moltiplicativa sotto certe condizioni:
- secondi di esecuzioni
- numero di operazioni elementari
- numero di volte una specifica operazione viene eseguita
  + piu' semplice

Una volta stabiliti i numeri di esecuzioni si passa all'analisi del caso migliore e del caso peggiore, si riconducono a polinomi

La *dimensione dell'ingresso* e' una misura della sua rappresentazione
- $|m| log_2 (m)+1$
- $|A[0...n-1]| nc$
  + $c$ numero bit del generico elemento di $A$
    - $c 1$ perche' le costanti moltiplicative non contano dal punto di vista dell'analisi asintotica

Fissato la dimensione esistano algoritmi per cui $T$ puo' cambiare rispetto alla forma dell'input
Distinguiamo i casi: migliore e peggiore
 - $T_{peggiore}(n) max{T()x}: |x|n$
 - $T_{migliore}(n) min{T()x}: |x|n$
Dobbiamo confrontare tra loro funzioni che hanno infiniti valori
- si trascura il numero finito di casi, conviene scegliere la funzione che cresce piu' lentamente all'infinito
  + se non ci interessano questi casi, se abbiamo informazioni in piu' allora vanno analizzati anche questi casi
Quanto contano le costanti?
- con un computer molto piu' veloce la dimensione massima trattabile cambia in maniera trascurabile
- la funzione che cresce meno velocemente e' comunque piu' importante di una costante moltiplicativa per il calcolo della complessita'
- inoltre la stima delle costanti e' molto difficile nella pratica

**** O-grande
Definito da P. Bachman, 1892.
$f(n) \in O(g(n)) \iff \exists c > 0, n_0 \forall n > n_0 \mid f(n) \le cg(n)$
Un $f(n)$ e' O-grande di $g(n)$ se e solo se $f(n)$ cresce al piu' come $g(n)$ dopo un numero finito di casi $n_0$ e eventuali costanti moltiplicative $c$.
Permette di specificare limiti superiori non stretti.
- $O(1)$
  + insieme delle funzioni superiormente limitate
    - la dimensione dell'input non ha impatto sul lavoro dell'algoritmo
Se $p(n)$ e' un polinomio di grado $k$ allora $p(k) in O(n^k)$

*Definizione equivalente*
$f(n) \in O(g(n)) \iff lim_{n \to \infty}\frac{f(n)}{g(n)}$ e
$0 \le lim_{n \to \infty} \frac{f(n)}{g(n)} < \infty$

*Teorema Utile*
$lim_{ n to infty}frac{f(n)}{g(n)} eq 0 <-> f(n) in O(g(n)) and g(n) notin O(f(n))$

- *NB*
  + nei polinomi cio' che conta e' il termine di grado piu' alto: il grado del polinomio
  + nei logaritmi non conta la base per O-grande
    + $O(\log_a n) = O(\log_b n), a,b >1$

- *Inclusioni*
  - $O(1) \subset O(\log n)$

  - $O(\log n) \subset O(n)$

  - $O(n) \subset O(n \log n)$

  - $O(n^p) \subset O(2^n)$

  - $O(2^n) \subset O(3^n)$
Il tempo di calcolo sufficiente alla risoluzione del problema é il suo confine superiore
- confine superiore alla complessitá di un problema
Il tempo di calcolo necessario alla risoluzione del problema
- confine inferiore alla complessitá del problema, per i tempi di calcolo di tutti gli algoritmi che risolvono il problema
- banali
  + dimensione del input
  + dimensione del output
  + eventi contabili
**** Omega
$\Omega$ limite asintotico inferiore
$f(n) \in \Omega(g(n)) \iff \exists c > 0, n_0 \forall n > n_0 \mid cg(n) \le f(n)$
$0< lim_{n \to \infty} \frac{f(n)}{g(n)} \le \infty$

**** Teta
\Theta limite asintotico sia inferiore sia superiore
$f(n) \in \Theta(g(n)) \iff \exists c_1 > 0,c_2 >0, n_0 \forall n > n_0 \mid c_1 g(n) \le f(n) \le c_2 g(n)$
$f(n) \in \Theta(g(n)) \iff f(n) \in O(g(n)) \land f(n) \in \Omega (g(n))$
$0< lim_{n \to \infty} \frac{f(n)}{g(n)} < \infty$
**** o-piccolo
$f(n) \in (g(n)) \iff \forall c > 0 \exists n_0 \forall n > n_0 \mid f(n) \le cg(n)$
$f(n)$ é un infinitesimo di $g(n)$

*** Somma-17

#+begin_example
Somma-17(V)
- Pre: V é un vettore che contiene numeri positivi
- Post: True se ci sono due numeri a,b t.c. a+b=17, False altrimenti

boolean b = False
for i=0 to length(V)-1
  for j=i+1 to length(V)-1
    if V[] + V[] == 17
      b = True
    end-if
  end-for
end-for
return b
#+end_example

$O(n^2)$ per il numero di volte che viene eseguito l'if nel caso peggiore
$\Omega(n)$ per la dimensione dei dati


_Soluzione di complessita' lineare_
#+begin_example
Somma-17-Lineare(V)

bool C[18]
int i, j
for i=0 to 17
  C[i] = False
end-for
for i=0 to length(V)-1
  if V[i] <= 17
    C[V[i]] = True
end-for
for i=0,j=17; i<j && !(C[i] && C[j]); i++,j--
end-for
return i < j
#+end_example
$T_{Somma-17-Lineare}(n) \in O(18+n+9+1) \in O(n)$
Questo implica che l'algoritmo é ottimo in quanto $\Omega(n)$ é confine inferiore del problema.

*** Minimo
$cn + d le T(n) le an+b$
- contenuto tra funzioni lineari
  + al piu' lineare
