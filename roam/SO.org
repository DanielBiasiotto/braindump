#+TITLE: Sistemi Operativi
#+COURSE: SO A
#+PROF: Davide Gunetti ~ Daniele.Gunetti@unito.it
#+STARTUP: latexpreview
[[file:#universita.org][#universit√°]]

* Generalita'
2 obiettivi di un OS:
- utente: rendere il sistema semplice
- macchina: rendere il sistema efficente e sicuro

- fornisce strumenti per uso corretto e semplice da usare
- Alloca risorse in maniera conveniente
- Controlla l'esecuzione dei processi per evitare pericoli

** Confine OS - Software

*** GUI all'inizio non parte del OS
Con Windows viene integrata

*** Comandi Shell
La shell non e' parte OS in Unix

** Kernel
E' il cuore del PC
gestisce
- programmi in esecuzione
- memoria principale
- memoria secondaria

** Gestione Eventi
*** L'OS generalmente non sta utilizzando le risorse
**** le gestisce e le fa usare ai programmi
**** puo' essere chiamato in causa dai programmi
<<<<<<< HEAD
        :PROPERTIES:
:ID:       98593566-3de2-4cb9-88c0-dafc002bed8a
:END:
=======
>>>>>>> 74e75ebd8fe4cc2f57b733ba168b84613c120970
*** puo' controllare che tutto sia in ordine
*** Interruzioni
Evento --> OS gestisce l'evento prendendo il controllo della macchina
- una volta gestito e' restituito il controllo ad uno dei programmi che stavano girando prima dell'evento
*** Interrupt
natura hardware
- segnali che richiedono intervento OS
*** Eccezioni
natura software
- causate dal' programma in esecuzione
  divese in
**** Trap
tentata divisione per 0
tentato accesso ad area protetta
**** System Call
richiesta di eseguire un operazione su un file
*** CPU segue dei passi predefiniti a livello hardware
- Salva lo stato della computazione
  + PC e altri valori della CPU in appositi registri
  + permette il riavvio del programma al punto di gestione evento
- in PC si scrive l'indirizzo in RAM della porzione di codice del OS che gestisce l'evento verificatosi
  + in =BootStrap=
    - OS carica in RAM
      + vettore delle interruzioni
        - ~n~ puntatori che indicano l'inizio dei codice di gestione eventi

      + Codice gestione evento ~n~
- return from event
  + ultima istruzione di ogni procedura di gestione
  + riprende l'esecuzione del programma precedente
** Struttura della Memoria
*** Principale - RAM
La memoria indirizzata alle istruzione eseguite
*** Secondaria - di Massa
Risiedono qui permanentemente dati e programmi
La gerarchia di memoria
- le memoria sono sempre piu' veloci ma di costo maggiore
- da fissse diventano volatili
- la componentistica per bit occupa piu' spazio
  + da condensatori passiamo ai Flip-Flop nei registri

La gerarchia di memorie e' una gerarchie di =Cache= di una rispetto alla precedente
- la RAM fa da cache per l'HD
  + le istruzioni di un programma sono copiate da HD a RAM per essere eseguite
- la Cache fa da cache per la RAM
- I Registri fanno da cache per la RAM
** Struttura di I/O
CPU connessa a dispositivi di I/O
- connessi da BUS
  Ogni dispositivo e' controllato da un =controller= hardware
  - ogni controller e' un piccolo processore
    + con
      - registri
      - memoria interna
        + =buffer=
          - dove il controller tradferisce i dati del dispositivo
  - OS interagisce con il controller
    + attraverso software:
      - =driver=
    + specifica nei registri del controller le operazioni da compiere
      - il controller eseguira' quello che gli e' specificato
      - una volta completato invia ~interrupt~ al driver
        + OS riprende il controllo

    Questa gestione e' adeguata solo per piccole quantita' di dati
    - inefficiente per moli maggiori
    - per inviare interi blocchi di dati dal controller al RAM
      + =DMA= Direct Memory Access
        - canale diretto tra dispositivo e RAM
        - OS tramite driver istruisce
          + prendi blocco numero n su HD e trasferisci in RAM a partire dalla locazione di indirizzo xxxx
** Multitasking & Time-sharing
*** Multitasking
Mantenere in memoria principale piu' programmi insieme ai dati di questi in modo da aumentare la ~produttivita'~
- quando un programma si ferma temporaneamente (per eseguire operazioni di I/O) l'OS ha gia' in RAM un secondo programma a cui assegnare la CPU
  + =job=

*** Timesharing
- interattivita'
- sistemi multi utente
  In caso la CPU non abbia tempo di idle durante l'esecuzione dei programmi
  - Il tempo di CPU sara' distribuito tra gli utenti e i loro programmi
    - da' l'impressione di simultaneita' (solamente apparente)
** Modalita' di Funzionamento
*** Doppia Modalita'
- Specificata da un bit di modalita'
- Esistono istruzioni protette che sono eseguibili solo in modalita' di sistema (quindi dall'OS)
  - i programmi utente usano le =system call= per operazioni che richiedono l'esecuzione di istruzioni privilegiate
    - l'OS gestisce e poi restituisce il controllo all'utente
  - realizzate attraverso eccezioni che cambiano il bit di modalita'

**** Normale
**** Sistema | Kernel | Monitor | Supervisor
*** Timer
~for(;;)i++;~  ciclo che non termina mai
- Per questi casi e' disponibile in CPU un Timer, dopo un certo tempo inizializzato dal OS viene inviato un =interrupt=
  - utilizzato anche in caso di Time Sharing
  - il timer e' gestito con istruzioni provilegiate
    - per evitare usi impropri malevoli
*** Protezione della Memoria
Evita la sovrascrittura delle aree di memoria di programmi in RAM da parte di altri programmi in esecuzione
- Soprattutto le aree dedicate all'OS
- Due registri in CPU
  - base
  - limite
    Ogni indirizzo generato dal programma in esecuzione viene confrontato con i valori contenuti nei registri
    - se non contenuto viene generata una =Trap=

** Strutture dei Sistemi Operativi
Livelli di complessita' e di accesso
- alcuni sono invisibili agli utenti
*** interfaccia col sistema operativo
non fa parte del kernel, ma e' fornito insieme all'OS
- interpreti di comandi | shell Unix
  - comandi == eseguibili
- GUI - interfaccia grafica
  - prima diffusione commerciale - ~1984~ Macintosh

*** programmi/servizi di sistema
non fanno parte del kernel, ma forniti insieme all'OS
rendono piu' semplice l'uso del sistema
- editor
- compilatori
- assemblatori
- debugger
- interpreti
- IDE
- browser
- gestori di email

*** chiamate di sistema
processo == programma in "esecuzione"
- un processo deve compiere una operazione privilegiata
  + System Call
- le system call sono la vera interfaccia tra processi e OS
  + procedure inserite in programmi scritti in linguaggi di alto livello
  + sembrano normali subroutine ma l'esecuzione e' portata avanti direttamente dal'OS
- esempi:
  + open() ~restituisce file descriptor~
  + write()
  + close()
  + fork()
- API
  + Application Programming Interface
  + strato intermedio tra applicazioni e system call
    - semplificano l'uso e la portabilita'
  + Api Windows / Api POSIX
  + esempi:
    - fopen() ~restituisce file pointer~
    - fprintf()
    - fclose()

*** gestione dei processi/memoria primaria/memoria secondaria
- =Processi concorrenti=
  + Competono per
    1. CPU
    2. spazio in memoria
    3. dispositivi INPUT/OUTPUT
- Gestione dei processi
  - Creazione | fork()
  - Sospensione e Riavvio
  - Sincronizzazione
  - Comunicazione
- Gestione Memoria Primaria
  - un programma in esecuzione e' caricato in memoria primaria (vedi Memoria Virtuale)
  - Time-Sharing
    - tenere traccia delle aree di RAM utilizzate e da che processo
    - distribuzione della RAM tra i processi
    - gestione dinamica della RAM
- Gestione Memoria Secondaria | File System
  - informazioni del sistema contenute in un =file=
  - file organizzati in una struttura gerarchica
    - =File System=
  - strumenti del OS
    - creazione
    - cancellazione
    - gestione file e directory
    - memorizzazione efficiente

*** protezione e sicurezza
Ogni processo deve essere protetto dalle attivita' improprie degli altri processi
- non deve essere possibile impadronirsi di una risorsa in modo esclusivo
- non devono essere accessibili aree di memoria assegnate ad altri processi

  Nessun utente puo' accedere a file di altri utenti

  =Macchine Virtuali=
  - ogni utente usa la VM indipendentemente dell'hardware
  - l'utente ha l'illusione di avere una CPU, un File System
    - nella realta' le risorse sono condivise

** Problemi

1) tener tracciatutti i programmi attivi nel sistema
   - stanno usando la CPU
   - richiedono l'uso della CPU
     - =processi= =thread=
2) CPU libera: a quale programma in RAM assegnare la CPU
3) interazione tra programmi senza danneggiarsi
   * evitare stallo
   * problemi di =sincronizzazione=
4) gestione della RAM
   * traccia delle aree di memoria occupate e da che programma
     * =memoria centrale=
     * =memoria virtuale=
5) gestione del File System
   * memoria di massa
   * fornire un'interfaccia
   * implementare il file system

** NB
- Single/Multi-Core
  + '90 CPU == singolo
    - un unico programma poteva utilizzare piu' CPU
    - sistema multiprocessore
      + tutti i processori condividono un'unica memoria principale
      + UMA
  + 2000
    - l'aumento delle prestazioni rallenta sensibilmente
    - processori costituiti da 2 processori affiancati sullo stesso _Die_
      + 2 Core
      + Processore Dual-Core
    - piccoli sistemi UMA
      + tutti i core possono indirizzare la stessa memoria principale
      + si condivide anche un livello di cache (L3) solitamente
- Non esiste una grande differenza tra OS per single-core o multi-core
  + in questo corso si presume che esiste un'unica unita' di calcolo
- OS di Rete e OS distribuiti

* Gestione Processi, Sincronizzazione
Componente del OS: =CPU Scheduler=
- Sceglie processi in coda di ready
- si attiva ogni 50/100 secondi
  - crea ~overhead~

** Processi
Unita' di lavoro del OS
- il primo ruolo del OS e' amministrare i processi
  - creazione
  - cancellazione
  - scheduling dei processi
  - sincronizzazione e comunicazione
    Un processo non e' solamente un programma in esecuzione
    - Struttura in Memoria =immagine del processo=
      - Codice
      - dati
      - stack
      - heap
    Un programma puo' definire piu' processi
    - un programma puo' contenere codice per generare piu' processi
    - piu' processi possono condividere lo stesso codice
    Fondamentalmente:
    - processo: entita' =attiva=
    - programma: entita' =statica=
    Un processo nasce sempre a partire da un'altro processo attraverso una opportuna =System Call=


*** =Stati= di un processo
L'OS sposta il processo tra vari stati attraverso cui esso evolve
- ~New~
  - Va assegnato ~Process Control Block~ e ~spazio in memoria~ necessario per il codice e i dati
  - questo e' gestito con interrupt, l'OS deve controllare subito perche' non conosce la naturea dell'interrupt e non puo' lasciare finire un processo in Running
- ~Ready~ (to run)
  - Scheduler Dispatch - componente del OS che sceglie e lancia il processo
  - Ci sono livelli di priorita' per i processi
    - un processo a bassa priorita' potrebbe rimanere in attesa del suo turno per sempre
- ~Running~
  - L'OS gira nel tempo tra un processo e l'altro, altrimenti sta in attesa (sleeps)
  - Se piu' processi: dopo un determinato tempo l'OS prende il controllo inviando un =interrupt=
    - il tempo di esecuzione puo' essere interrotto da interrupt ma verra' poi restituito subito dopo al processo in questione
- ~Waiting~
  - Il processo puo' aver richiesto una operazione di I/O (con una System Call)
    - queste operazioni sono sotto il controllo del OS, quindi sara' questo a interrompere il Waiting una volta completate
- ~Terminated~
  - Il processo termina
  - L'OS riprende il controllo per ripulire la memoria dall'area occupata dal processo ora terminato
**** =diagramma= di transizione degli stati di un processo
- Rimuovere l'arco interrupt
  - da' il diagramma di un OS multitasking ma non time-sharing

*** Process Control Block - =PCB=
- Process ID
- Stato
- Contenuto dei registri della CPU una volta sospeso il processo
- Indirizzi RAM aree dati e codice
- File in uso
- Informazioni Scheduling

  E' il PCB del processo che viene inserito in coda di ready dopo che l'OS ha recuperato il codice e caricato in RAM

#+NAME: Crezione di un processo in Unix
#+BEGIN_SRC C
int main(){ //NB: ad un programma possono corrispondere piu' di un processo
    pid_t pid, childpid;
    pid = fork(); //genera un nuovo processo copiando codice e dati del padre,
                  //nel PID indica gli indirizzi che lo riguardano
                  //nella cella di memoria del PID padre scrive il PID del figlio
                  //nella cella di memoria del PID figlio scrive 0
    printf("questa la stampano padre e figlio"); //sia padre che figlio riprendono dopo il fork
    if(pid == 0){
        printf("processo figlio");
        execlp("/bin/ls", "ls", NULL); //specifica il codice da eseguire, NB non ritorna
    }
    else{ //eseguito dal padre in quanto in pid contiene un numero maggiore di 0
        printf("sono il padre, aspetto il figlio");
        childpid = wait(NULL); //Waiting Queue, i due processi si sincronizzano
                               //a processo figlio terminato viene scritto il PID figlio
                               //a questo punto il padre viene reintrodotto nella Ready Queue
        printf("il processo figlio e' terminato");
        exit(0);
    }
} //System Call: fork(), execlp(), wait(), exit()
#+END_SRC
Il codice e' copiato solo concettualmente, le aree dati sono realmente duplicate
- System Calls utili
  - getpid()
    - restituisce il process Id del processo chiamante
  - getppid()
    - restituisce il process Id del parent del processo chiamante

*** Operazioni su processi
**** Creazione
- ogni OS possiede almeno una ~System Call~ di creazione
  - tutti i processi nascono da altri processi ~con l'eccezione~ di quello all'accensione del Sistema
- nel sistema si forma un =albero di processi=
  - Il Creatore e' detto Padre - =parent=
  - Il Creato e' detto Figlio  - =child=

    Nel Creare un albero l'OS riferisce i processi con un ~PID~ (Process ID) ovvero un identificatore
    - Comando:
      - ps - process status

#+SOURCE-START
***** Scelte ingenieristiche
Moderni OS implementato tutte queste combinazioni nelle loro System Call
****** Avvio
******* Processo padre continua concorrentemente al figlio - ready queue
******* Processo padre di ferma attendendo l'esecuzione del figlio - waiting queue
****** Esecuzione
******* Fornire al figlio copia del codice padre
******* Nuovo programma al figlio
**** Uccisione
- kill / TerminateProcess(Win)
  - secondo PID
  - puo' avvenire se =TRAP=

*** Comunicazione tra processi

**** indipendenti

**** cooperanti
si influenzano l'un l'altro
- si scambiano informazioni
- portano aventi una elaborazione suddivisa
  Per permettere cio' l'OS deve mettere a disposizione meccanismi appositi

***** Inter-Process Communication =IPC=
L'OS mette a diusposizione System Call volte all'implementazione di:
- memoria condivisa
  - sovrascritto il divieto della memoria dell'altro processo
  - Scelte  implementative
    - dimensione variabile?
    - che processi hanno diritto di uso?
    - un processo

- scambio di messaggi
  - coda di messaggi
    - gestita dal OS
      - Scelte implementative
        - coda usata da piu' di due processi?
        - limite alla dimensione della coda?
        - ricevente se non ci sono messaggi? sospensione?
        - trasmittente se la coda e' piena?  sospensione?
    Esempi di System Call
    - msgget()
    - send(message, line, PID)
    - receive(message, line, PID)

****** Pipe

****** Client-server

******* Socket

******* Remote Procedure Call =RPC=

***** esempio
processo =produttore=, produce informazioni utilizzate da un processo =consumatore=
- informazioni poste in un =buffer=

  =produttore=  - Compilatore  ~ produce codice oggetto
  =consumatore= - Assemblatore ~ consuma codice oggetto

#+BEGIN_SRC C
#define SIZE 10
typedef struct {...} item;
item buffer [SIZE];
int in = 0, out = 0;
#+END_SRC
in: prossimo item libero
out: primo item pieno
buffer vuoto: in=out
buffer pieno: in+1 mod SIZE = out --il buffer e' utilizzato in modo circolare
NB: Il buffer pieno usera' ~SIZE-1 posizioni~
#+NAME: Consumatore
#+BEGIN_SRC C
item nextp;
repeat
while (in == out) // empty buffer
    do no_op;
nextp = buffer[out];
out = out+1 mod SIZE;
<consuma l'item in nextp>
until false;
#+END_SRC

#+NAME: Produttore
#+BEGIN_SRC C
item nextp;
repeat
<produci nuovo item in nextp>
while(in+1 mod SIZE == out) // full buffer
    do no_op;
buffer[in] = nextp;
in = in+1 mod SIZE;
until false;
#+END_SRC

** Thread

** Scheduling
Presupponendo un sistema Single-core
L'OS fa credere ai processi di avere tutta la CPU per loro
- Process Switch/Context Switch
  - L'=unico= PC viene aggiornato con i valori relativi al processo Running

    NB: Diagramma di Gantt

*** Context Switch
Passaggio da un processo in esecuzione all'altro
=Commutazione= della CPU tra i processi
- OS prende il controllo CPU ~ questo e' tecnicamente pure un Context Switch
- Salva lo stato della computazione del processo uscente in PCB
- Scrive in PC e nei registri CPU i valori PCB del processo entrante

  Questa operazione richiede tempo: ~overhead~ di sistema (sovraccarico)

*** Code di Scheduling
OS gestisce varie code di processi
- una lista di =PCB=

- Coda di Ready ~ Ready Queue ~ =RQ=
  - coicide con lo stato Ready nel ~diagramma~

- n Code di Waiting
  - Code dei dispositivi ~Device Queues~
    - piu' processi possono essere in coda per l'accesso ad un dispositivo
  - Code di Eventi       ~Waiting Queues~

**** Diagramma di accodamento
riformulazioe del diagramma di transizione prendendo in considerazione le code

*** Implementazione
Tecniche per massimizzare la produttivita' della CPU
- [[Multitasking]]
- [[Time Sharing]]
  Per cio' devono essere definite delle regole dal progettista

  I processi vivono fasi di ~CPU-burst~ e ~I/O-burst~
  I processi possono essere
  - CPU-bound
    - un compilatore x es
  - I/O-bound
    - un browser
    - un editor

**** Scheduler
decide quale processo in coda di ready sara' eseguito quando:
1. il processo in esecuzione passa volontariamente in stato di waiting
2. il processo in esecuzione termina
3. il processo in esecuzione viene ~obbligato~ a passare allo stato di ready
   - questo con un timer hardware - =vettore delle interruzioni=
4. un processo \(P_x\) entra in coda di ready arrivando da un coda di wait oppure e' sato appena lanciato
   1) l'OS interviene per gestire il =PCB= di \(P_x\) spostandolo in coda di ready
   2) se \(P_x\) e' piu' importante del processo in esecuzione

      per 1. 2. e' sufficiente un OS multitasking

**** Dispatcher
- implementa il [[Context Switch]]
- passa in user mode
- ripristina il PC della CPU alla corretta locazione

**** senza diritto di prelazione
=non-preempive scheduling=
Casi 1. e 2.
- I processi non posso interrompere l'esecuzione di altri processi

  Implementazione piu' snella utilizzata per OS specifici
**** con diritto di prelazione
=preemptive scheduling=
Casi 1. 2. 3. e 4.
- I processi non possono eseguire a tempo indeterminato
- I processi possono avere priorita' diverse

  Implementazione utilizzata per OS general purpuse

  Se una =System Call= chiamata dal processore in esecuzione viene ~interrotta dal vettore di interrupt~?
  - la prima istruzione della System Call puo' essere un'istruzione che
    - ~disattiva gli interrupt~
  - ultima istruzione
    - ~riabilitazione degli interrupt~

**** Criteri
Obiettivi:
- massimizzare =uso CPU=
- massimizzare il =Throughput=
  - ovvero la produttivita'
  - minimizzare il =tempo di risposta=
    - importante per i processi interattivi
- minimizzare il =Turnaround time=
  + tempo medio di completamento di un processo
    + da quando entra per la prima volta in coda di ready fino a quando non termina l'esecuzione in stato running
      - per semplificare non si considera la creazione e la terminazione del processo
- minimizzare il =Waiting time=
  + somma del tempo passato dal processo in ~coda di Ready~

~Turnaround Time~ = WaitingT + RunningT

**** Algoritmi
Considerando in questo corso processi con un =unico burst di CPU= e =nessun burst di I/O=

Un Algoritmo tanto √© migliore quanto le sue prestazioni di avvicinano da =SJF= allontanandosi da =FCFS=

~def~
***** Starvation
+ il processo non viene mai scelto in quanto mai di priorit√°
  * Aging
    + il processo aumenta di priorit√° con il tempo passato in RQ

***** First Come, First Served
=FCFS=
***** Normale coda FIFO
+ PCB inserito in fondo alla coda
+ CPU libera assegnata al primo PCB alla testa
****** Non-preemptive
+ non implementa time-sharing
******* Tempo di attesa elevato
+ Effetto convoglio ~ accodamento job piu' corti

  Osservazioni
  - sfavorisce i processi brevi
  - non implementa sistemi time-sharing

  Peggiore degli Algoritmi ragionevoli

***** Shortest Job First
=SJF= ~ Shortest Next CPU Burst
- Esamina la durata del prossimo burst di CPU dei processi in RQ
- assegna la CPU al processo con burst minimo
- Pu√≥ essere ~preemptive~ o ~non-preemptive~
  1) Preemptive - =Shortest Remaining Time First= =SRTF=
     + se in RQ √© presente un processo il cui ~CPU-burst √© minore del tempo di esecuzione rimanente~ al processo Running, ha la priorita' il nuovo processo e viene interrotto quello in stato Running
       + Ipotesi solamente teorica

     √â dimostrabile che SJF √© ~ottimale~
     + spostando un processo breve prima di uno lungo
       - si migliora l'attesa del processo 1 pi√∫ di quanto di peggiori l'attesa del processo lungo
         + quindi diminuisce alche il Turnaroud-time medio

     ~MA~
     la durata del prossimo burst di CPU non √© nota
     + SJF non √© implementabile

***** Priority scheduling
=PS=
calcolo della priorit√°:
- interna al sistema
  + sulla base di ogni processo
- esterna al sistema
  + sulla base del utente
    Pu√≥ essere ~preemptive~ o ~non-preemptive~



***** Round Robin
=RR=
L'algoritmo di implementazione del time-sharing, la RQ e' utilizzata come una coda circolare
- ogni processo ha un ~quanto di tempo~ implementato da un timer hardware che invia un interrupt allo scadere del tempo
  + entro il suo tempo il processo non lascia la CPU se non per wait
  + alla fine del suo tempo il processo √© interrotto
- il prossimo processo ad andare in esecuzione sar√° il primo in RQ
Con \(n\) processi in coda di ready e il quanto di tempo \(q\) ogni processo riceve \(1/n\) del tempo della CPU e nessun processo aspetta pi√∫ di \((n-1)q\) unit√° di tempo

- Turnaround medio peggiore di SJF
  + ovviamente
- Tempo di risposta medio migliore di SJF


Prestazioni dipendenti da \(q\):
- \(q \to\infty\)
  + RR == FCFS
- \(q\to 0\)
  + aumenta l'illusione di ~parallelismo~
  + aumenta il numero di ~context switch~

- regola empirica
  + \(80\% \text{ dei CPU burst} < q\)


***** Multilevel Queue
=MQ=
Code multiple
- foreground -- RR
  + interagiscono con l'utente
- background -- FCFS
  + non interagiscono
- batch
  + la loro esecuzione pu√≥ essere differita

Si pu√≥ suddividere la RQ in pi√∫ code
+ gestire ogni coda con un algoritmo ottimale
+ Scelta:
  - priorit√° fissa
    - possibile starvation
    - time slice
      - quanti di tempo maggiori per foreground, minori per background  e batch

***** Multilevel Feedback Queue
=MFQS=
Code multilivello con retroazione
- I processi possono essere promossi a code a piu' alta priorit√° o retrocessi
- assegnamento a coda dinamico
  - i processi sono spostati dal OS per
    + adattarsi alla lunghezza del CPU burst
    + gestire ogni coda con lo scheduling adatto rispetto al comportamento mostrato

- Es
  - se il processo esaurisce il quanto assegnato dalla prima coda RR, sara' spostato alla coda RR successiva con un quanto maggiore
  - se il processo esaurisce i quanti delle code RR sar√° spostato in una coda FCFS

**** Multielaborazione Simmetrica
=SME=
- scheduler per ogni core
  + code condivise
    + sincronizzazione
- code private ai core ~ preferita dagli OS moderni
  - necessario un sistema di bilanciamento tra le RQ dei core
    + difficolt√° dovute a cache a pi√∫ livelli
      - dati e istruzioni di un processo sono man mano indirizzati e copiati nei vari livelli di cache
      - se spostato su un'altro core le informazioni vanno recuperate in quanto contenute in cache private di un altro core
        +
      - OS possono relegare un processo particolare ad un unico core per questo motivo



*** Esempi di Scheduling

*** Solaris
    - Scheduling a code multiple con retroazioine
      1. real time
      2. sistema
      3. interattiva
        - 60 livelli di priorit√° - 50-59
      4. timesharing
        - 60 livelli di priorit√° - 0-40

    Di norma i processi nascono nella classe _timesharing_
    I processi seguono priorit√° formattate cos√≠:
    | Priority | Quantum[m/s] | New priority (exhausted quantum) | New priority (unexhausted) |
    |        0 |          200 |                                0 |                         50 |
    |      ... |          ... |                              ... |                        ... |
    |       59 |           20 |                               49 |                         59 |

    I processi possono essere promossi o meno in base al quanto che hanno sfruttato
    - maggiore √© la priorit√° maggiore √© la probabilit√° che verr√° scelto per l'esecuzione al prossimo ciclo ma minore sar√° il quanto a lui assegnato dal OS
    Processi di sistema e real time hanno priorit√° fissa, maggiore di interattiva e time sharing
    - lo scheduler calcola la priorit√° globale di un processo
      + priorit√° == si usa RR
      + algoritmo preemptive

*** Windows
    Priorit√° con retroazione e prelazione
    - 32 livelli
      + real time - 16-31
      + altri - 1-15

    Lo scheduler sceglie il processo a priorit√° pi√∫ alta
    - se il processo va in wait
      + viene alzata la sua priorit√°
        - dipendentemente dalla tipologia del wait
          + se √© atteso un dato dal disco l'aumento √© minore
    - in caso di priorit√° uguale √© utilizzato il RR
      + se il quanto viene esaurito la sua priorit√° √© abbassata
        - limite 1
    Favorisce i processi che interagiscono con mouse e tastiera
    Inoltre W distingue tra background e foreground
    - il processo foreground ottiene 3 volte l'aumento del quanto di tempo che gli altri processi

*** Linux
    Completely Fair Scheduler =CFS=
    Cerca di distribuire a tutti i processi equamente il tempo di CPU

    Ad ogni context switch lo scheduler calcola il quanto tempo che spetta ad un processo P in modo che tutti i processi abbiamno avuto la stessa quantit√° di tempo di CPU
    - P.vruntime = P.expected_run_time - P.due_cputime
      - CPU data al processo con P.vruntime pi√∫ basso
        - CPU-use minore
    - i processi ready-to-run sono nodi di un albero di ricerca bilanciato: =red-black tree= o R-B tree
      + permette operazioni molto efficienti
        - O(logx)
      + i nodi sono inseriti con la chiave del P.vruntime
        - il nodo pi√∫ a sinistra sar√° quello scelto dallo scheduler


** Sincronizzazione
<<<<<<< HEAD
    I processi possono cooperare, perci√≥ dovranno condividere dei dati
    - √© necessario evitare la creazione di ~dati inconsistenti~

    Devono sincronizzarsi
    ~Problema~
    - mentre P1 elabora dati che verranno usati da P2 viene rimosso dall'esecuzione
      + P2 non dovr√° lavorare sui dati incompleti lasciati da P1

    - esempio
      + produttore - consumatore
        - utilizzata variabile condivisa buffer/counter (buffer circolare)
          - se produttore esegue counter++ 'mentre' consumatore esegue counter--

            + questo pu√≥ verificarsi perch√© quella eseguita non √© una operazione ~atomica~, non utilizzano una sola istruzione ISA a livello di architettura

    La sincronizzazione √© un problema solamente se si effettuano scritture su memoria condivisa
    - le operazioni da sincronizzare devo concludersi completamente e non essere interrotte dallo scheduler per passare al processo sincronizzato dati consistenti
    Va sviluppato un protocollo usato dai processi che vanno ad usare variabili condivise
    Il codice sar√° strutturato in questo modo:
                    =entry section=
      - richiesta di entrare nella sezione critica
                   =sezione critica=
                     =exit section=
      + segnalazione di uscita dalla sezione critica

    Una soluzione al problema avr√° queste propriet√°
    - Mutua Esclusivit√°
      + mai ci saranno conflitti di accesso
    - Progresso
      + se la sezione critica non sta venendo eseguita allora un processo in futura ne avr√° accesso
      + questo garantisce l'assenza di =deadlock=
    - Attesa Limitata
      - qualsiasi processo che richiede di accedere alla sua sezione critica non soffrir√° di =starvation=
      - evitare attese infinite

    Una soluzione corretta deve permettere ai processi di computare indipendentemente dalla loro velocit√°
    - non deve dipendere dallo scheduling del sistema


*** Sezione Critica
    Zona del codice di manipolazione delle variabili condivise, non deve ~intrecciarsi~ co altre sezioni critiche
    - se un processo \(P_i\) sta eseguendo una sua sezione critica allora altri processi \(P_j\) non possono eseguire la propria
    - L'esecuzione della sezione critica di un \(P_i\) √© mutualmente esclusivo con l'esecuzione delle sezioni critiche di altri \(P_j\)
      - anche se interrotto dalla scheduler nessun altro processo maniplante


**** Nel Sistema Operativo
    - accesso contemporaneo alla tabella dei file aperti
    - uso contemporaneo della fork
      + devono avere diversi PID
    In un sistema operativo il problema √© risolto con una scelta
    - kernel con diritto di prelazione
      - un processo in kernel-mode pu√≥ essere interrotto da un altro processo
      - migliore per un sistema per applicazioni real-time
        + minore tempo di risposta
    - kernel senza diritto di prelazione
      - in kernel-mode un processo non pu√≥ essere interrotto
      - implementazione semplice: _disattivazione degli interrupt_
      - un solo processo alla volta pu√≥ accedere alle strutture dati dei kernel
        - accesso in modo esclusivo al codice della System Call

    Soluzione:
    - istruzioni macchina particolari
      + TestAndSet(v)
        #+begin_src C
boolean TestAndSet(boolean *lockvar){
    boolean tempvar = *lockvar;
    *lockvar = true;
    return tempvar;
}
        #+end_src
        Poi usata cos√≠
        #+begin_src C
boolean lock = false; // shared var
do{
    while(TestAndSet(&lock)); // while senza corpo
    //sezione critica            qui la variabile di lock == true
    lock = false;             // quando l'altro processo eseguir√° il ciclo passer√° il test
} while(true);
        #+end_src
        - In questo modo se un altro processo che testa lock rester√° nel while in quanto _while(&lock) == while(true)_
        - l'_Attesa Limitata_ non √© garantita
          - un processo potrebbe uscire dalla sezione critica e rientrarci nello stesso quanto di tempo
          - un meccanismo di aging non serva in quanto i processi entrano in esecuzione solamente che non riescono ad eseguire
          - pu√≥ essere implementata con una versione pi√∫ complessa
        - _Busy Waiting_:
          + il processo che tenta di accedere ad un lock fa busy-waiting
            - in quanto cicla in base ad una variabile che √© modificabile sola da un altro processo
              + con un RR:
                - con \(N\) processi lo spreco di tempo di CPU sar√° \(N-1\) quanti di tempo
            - risolvibile con la disattivazione degli interrupt
              + perdita di controllo per un tempo arbitrario del OS
              + ci si deve fidare che il processo riabiliter√° gli interrupt
      + Swap(\(v1\),\(v2\))

    Queste sono istruzioni macchina e quindi _atomiche_, non saranno mai interrotte a met√° da un context switch
    I passi sono:
    - il processo tenta di accedere al lock
    - esegue la sezione critica
    - restituisce il lock

    ~NB~ La mutua esclusione in sistemi multi-core √© pi√∫ complessa


***** Semafori
    Dijkstra - 1965
    Semaforo \(S\): variabile strutturata operabile tramite operazioni atomiche:
    - wait(S) ALIAS: P, down
      #+begin_src C
while S <= 0 do no-op;
S= S-1;
      #+end_src
    - signal(S) ALIAS: V, up
      #+begin_src C
S =S+1;
      #+end_src

      \(S\) √© detta variabile semaforica, come se fosse un oggetto condiviso da tutti i processi per la sincronizzazione

    La variabile la chiameremo _mutex_ (mutual exclusion)
    #+begin_src C
P {
    do{
        wait(mutex);
        // sezione critica
        signal(mutex);
    } while(true);
}
    #+end_src

=sync=
    #+begin_src C
sync = 0;
P1{
    S1;
    signal(sync);
}
P2{
    wait(sync);
    S2;
}
    #+end_src

Questo tipo di semafori soffre ancora di busywaiting, sono chiamati _spinlock_
Soluzione implementata utilizzando System Call
- lista di semafori memorizzata nelle aree dati del kernel
- System Call
  + sleep() ALIAS: block()
    - toglie il processo dall'esecuzione
      + non viene inserito nella Ready Queue
  + wakeup()
    - rimette il processo in Ready Queue
- implementazione
  #+begin_src C
typedef struct{
    int valore; // se > 0 indica sezione critica libera
    struct process *waiting_list;
}semaforo;

wait(semaforo *S){
    S->valore--;
    if S->valore < 0 {
            // aggiunto processo a S in waiting_list
            sleep(); // il processo si √© addormentato sul semaforo
    }
}

signal(semaforo *S) {
    S->valore++
    if S -> valore <= 0 {
            // togli un processo P da S -> waiting_list
            wakeup(P); // risvegliato P, va in Ready Queue
    }
}
  #+end_src

- NB
  - wait e signal sono _esse stesse sezioni critiche_ perch√© usano le stesse aree dati
    - risolvibile con una interruzione di interrupt o con busywaiting perch√© queste sono System Call e molto brevi
      + interruzione degli interrupt in multiprocessori non ovvio: sono disattivati solo su un particolare core

  - \(|mutex|\) = numero di processi addormentati
    - una S < 0 indica (in valore assoluto) il numero di processi addormentati su quel semaforo
      + se mutex = 1 allora \(P_1\) entra e \(mutex = 0\), context switch
      + un \(P_2\) testa mutex, \(mutex = -1\), \(P_2\) si addormenta

  - Utilizzabile un valore di semafori > 1 allora una risorsa √© utilizzabile da 3 P contemporaneamente

  I semafori se utilizzati non correttamente possono provocare _deadlock_ e _starvation_
=======
>>>>>>> 74e75ebd8fe4cc2f57b733ba168b84613c120970

**** Esempi
    Problemi di sincronizzazione risolti utilizzando semafori

***** Produttori e Consumatori
    - buffer circolare[SIZE]
      + memoria condivisa da tutti i produttori e tutti i consumatori
    - semafori
      + full
      + empty
      + mutex
    - in
    - out

    #+name: Produttore
    #+begin_src C
while(true){
    produciItemInNextp();
    wait(empty);
    wait(mutex);
        buffer[in] = nextp;
        in = in++ mod SIZE;
    signal(mutex);
    signal(full);
}
    #+end_src
    #+name: Consumatore
    #+begin_src C
while(true){
    wait(full);
    wait(mutex); // in caso di pi√∫ consumatori e pi√∫ item nel buffer
        nextc = buffer[out];
        out = out++ mod SIZE;
    signal(mutex);
    signal(empty);
    consumaItemInNextc();
}
    #+end_src
***** Lettori e Scrittori
    Condivisione di un file tra molti processi
    - alcuni processi richiedono la sola lettura
      + possono essere paralleli
    - alcuni richiedono la scrittura
      + richiede la mutua esclusione di tutti i processi
****** Readers First
    Variabili:
    - condivise
      + semaforo mutex = 1
      + semaforo scrivi = 1
      + int numlettori = 0
    #+name: scrittore
    #+begin_src C
wait(scrivi);
scriviFile();
signal(scrivi);
    #+end_src
    #+name: lettore
    #+begin_src C
wait(mutex);
numlettori++;
if numlettori == 1
    wait(scrivi);
signal(mutex);
leggiFile();
wait(mutex);
numlettori--;
if numlettori == 0
    signal(scrivi);
signal(mutex);
    #+end_src

    E' garantita l'assenza di Deadlock e Starvation?
    - no
      - uno scrittore addormentato su scrivi dovra aspettare la terminazione di tutti i lettori, se continuano ad aggiungersi lettori ci sara' un Deadlock

****** Writers First

****** Fair

***** Cinque Filosofi
    - 1 tavolo circolare
      + 5 posti
      + 5 piatti
      + 5 bacchette condivise
        - 2 necessarie per mangiare
    Ogni risorsa e' associata ad un semafori in un array
    #+begin_src C
do{
    wait(bacchetta[i]) // context switch qui causa Deadlock
                       // Attesa Circolare
    wait(bacchetta[i+1 mod 5]);
        mangia();
    signal(bacchetta[i]);
    signal(bacchetta[i+1 mod 5]);
        pensa();
}while(true);
    #+end_src

** Deadlock
    Programma A aspetta informazione dal Programma B che aspetta...
    Il deadlock non √© affrontato dagli OS, deve essere gestito dall'OS
    - se uno dei dui processi cede il passo risolviamo la deadlock ma non la =starvation=

    _Modello del Sistema_
    - Tipi di risorse R
      + ognuna formata da istanze indistinguibili tra loro
    - Processi P
      + hanno bisogno di alcune istanze di R
    In una situazione di attesa circolare le risorse possono rimanere bloccate, quindi questo √© un problema di tutto il sistema
    L'OS potrebbe implementare delle soluzioni con adeguate rappresentazione del _grafo di assegnazione delle risorse_
    - se si verifica un ciclo in questo grafo √© chiara la situazione di deadlock e allora viene risolta
      - causa un sottoutilizzo delle risorse (poich√© non evita i deadlock di per se)
    - oppure si potrebbe evitare i deadlock verificando prima di concedere una risorsa che questa non porti ad una attesa circolare
      - troppo dispendioso dal punto di vista della computazione per l'OS

* Gestione Memoria

** Centrale
Bisogna decidere come spartire lo spazio di memorizzazione tra i processi attivi
- _l'immagine_ di un processo inattivo nei prossimi cicli di CPU puo essere spostato su hard disk
- quando un processo rientra in RAM occupera' spazio prima occupato
Questo e' lo ~swap~
*** Binding
Associazione degli indirizzi
- ad ogni variabile di un programma va associato un indirizzo che ne contiene il valore
- alle istruzioni di salto va associato l'indirizzo di salto in caso questo avvenga

_In fase di Compilazione_
- generato codice assoluto o _statico_
- il compilatore deve conoscere l'idirizzo della cella a partire dalla quale verra' cariato il programma per poter portare a termine il binding
- se il processo e' spostato in memoria secondaria
  + dovra essere messo allo stesso indirizzo
  + o ricompilato ad un nuovo indirizzo

_In fase di caricamento in RAM_
- generato codice _staticamente rilocabile_
- il compilatore associa indirizzi relativi all'inizio del programma (indirizzo 0)
- indirizzi assoluti generati in fase di caricamento
- se il processo e' spostato in memoria secondaria
  + piu' efficiente in quanto e' in fase di caricamento che vengono risolti i riferimenti

_In fase di esecuzione_ aka ~binding dinamico degli indirizzi~
- generato codice diamicamente rilocabile
- il codice utilizza sempre e solo indirizzi relativi
  + questi sono risolti solo al momento dell'esecuzione dell'istruzione in particolare
- necessita un supporto hardware per non perdere efficienza
  + registro di rilocazione
    - indirizzo di partenza in cui e' caricato il programma in esecuzione
  + MMU
    - risolve gli indirizzi in assoluti
- cosi non ci son
 
**** Librerie
2 tipi:
- Statiche
  + Associata dal compilatore o dal loader e collegata al programma in memoria
    - anche se la subroutine non e' utilizzata viene memorizzata in memoria principale
  + Ogni programma dovra' avere una copia del codice della libreria in quanto direttamente associati
  + provoca dublicazione del codice in memoria
- Dinamiche
  + caricate a runtime
    - solo dopo una specifica invocazione in corso di esecuzione il Sistema Operativo interrompe e carica in RAM il necessario prima di ridare il controllo al programma
  + diversi programmi condividono la stessa porzione di codice in RAM se chiamano la stessa libreria
    - viene carica un sola volta eliminando la dublicazione di codice
  + una nuova versione della libreria e' automaticamente caricata dal programma, non ci sara' bisogno di ricompilare i moduli per compilare la nuova libreria

*** Spazi degli indirizzi
:PROPERTIES:
:ID:       e20e286c-f8ae-48a6-9447-a94f3588f4cd
:END:
tag: [[file:20201102165014-ram.org][Memorie]]

Ogni indirizzo di un programma in un sistema allocato dinamicamente sar√° sempre compreso tra $0$ e un $max$
- Questo spazio e' chiamato spazio degli indirizzi o _spazio di indirizzamento logico_
- Gli indirizzi sono definiti =logici= o =virtuali=
  + questi sono convertiti in indirizzi =fisici= dal registro di rilocazione
    - somma del registro e del registro logico a livello hardware
    - indicano una determinata cella in RAM
- Analogamente c'e' uno _spazio di indirizzamento fisico_
  - da $r+0$ a $r+max$

=NB=: il numero di bit per la memorizzazione degli indirizzi logici puo essere diverso da quello per la memorizzazione degli indirizzi fisici
- allora lo spazio degli indirizzi logici sara' piu' piccolo in quella architettura
  + un programma avra' un limite di grandezza e memorizzazione
Questo e' il caso piu' frequente, infatti in caso di indirizzi fisici a 64 bit, questi sono troppi in casi normali:
- sono indirizzabili $2^{40} B$ ovvero $1 TB$ con un indirizzamento di 40 bit
Solitamente vale questa relazione:
\(|RAM|_{effettiva}<|RAM|_{max}<<|PhisSpace|<|VirtSpace|\)
- Questo e' possibile grazie la memoria virtuale

*** Tecniche di Gestione della memoria
**** Swapping
Salvataggio in memoria secondaria di un =immagine= del processo non in esecuzione (~swap out~) e ricaricarla successivamente (~swap in~)
- =area di swap=
  + area di harddisk ad uso esclusivo del OS
- l'operazione di =swap in= posiziona il processo in una diversa area di MP
  + viene aggiornato il =registro di rilocazione=
- grande ~overhead~ causato dallo spostamento su disco
  + tecnica abbandonata
    - ora sostituita dalla memoria virtuale
      + e' spostato solo una parte del programma
**** Allocazione contigua a partizioni multiple fisse
NB: tecnica utilizzata dal IBM OS/360
Memoria Principale suddivisa in 2 _partizioni_
- OS
- Processi Utente
  + occupata solo un processo nei casi piu' semplici
  + =registro limite= protegge la memoria primaria riservata al OS
  + un registro di rilocazione permettera' la risoluzione del indirizzo fisico
  + Le partizioni sono di dimensione fissa
    - non necessariamente uguali
    - ogni processo puo' accedere solo alla sua porzione
      + registri di rilocazione a ggiornati ad ogni context switch
      + registro limite aggiornato con la dimensione della partizione
_Limiti_
- Questa tecnica limita il grado di ~multiprogrammazione~ al numero di partizioni previste
- Inoltre si verifica ~frammentazione~
  + interna perche' nessun processo occupera' esattamente la partizione assegnata
  + esterna perche' le frammentazioni interne si sommano per uno spreco globale
**** Allocazione contigua a partizioni multiple variabile
_Partizioni_ misurate sulla grandezza dei processi
- Questo crea buchi di RAM sempre piu' piccoli e numerosi tra i processi durante l'evoluzione dell'esecuzione
  + sara' sempre piu' difficile utilizzare lo spazio in quanto troppo frammentato
_Scelta della partizione_
- First Fit
  + utilizzata prima partizione abbastanza grande
- Best Fit
  + utilizza piu' piccola partizione abbastanza grande
- Worst Fit
  + utilizza la partizione piu' grande
_Limiti_
- Frammentazione esterna aumenta con il tempo
- Frammentazione interna in quanto costa troppo tenere traccia dei buchi tra i processi e questi rimarranno nascosti
_Soluzione_
- Rilocazione dei processi in maniera contigua
  + quindi sara' necessaria una implementazione dinamicamente rilocabile
  + verso il basso o l'alto
- Compattamento
  + creazione di un unica area libera di memoria
**** Paginazione
Area di memoria allocata da un processo suddivisa in pezzi _non contigui_
- ~Frame~ o ~Pagine Fisiche~
  + pezzi di dimensione fissa in cui e' divisa la Memoria Principale aka spazio di indirizzamento fisico (potenze di 2)
    - a differenza dalla =segmentazione=
- ~Pagine~
  + pezzi di dimensione identica ai frame in cui e' suddiviso lo spazio di indirizzamento logico

L'OS carica $x$ pagine cercando $x$ frame liberi, il cui ordine e posizione non e' importante

_Architettura di Paginazione_
- =Page-Table=
  + array con cui tiene traccia degli indici di pagine e frame
- Traduzione Indirizzi Logici
  + questo implementa la =traduzione= tra indirizzi paginati logici a indirizzi paginati fisici
    - pagina $p$ indice della tabella per ottenere il frame $f$ che lo contiene
      + nella entry $p$ si trova l'indirizzo di partenza del frame puntato
    - offset $d$ (displacement) utilizzato a partire dall'indirizzo fisico del frame $f$
      + questo e' sommato all'indirizzo puntato da $p$ nella tabella delle pagine per ricavare l'indirizzo fisico
- Elenco dei frame liberi
  + aggiornato ogni volta che e' necessario
   
_Indirizzi Logici_ reimplementati
- non piu' lineari
- nuova implementazione
  + coppia di valori =(page, offset)=
    - numero della pagina da indirizzare
    - offset rispetto all'inizio della pagina


L'hardware impone alcune dimensioni
- bit indirizzo logico - $m$
- dimensione del frame - $2^{n}$
  + $n$ bit di offset
  + $m-n$ bit per indirizzare le pagine
- Spazio di Indirizzamento Logico
  + $2^{m-n}\times 2^{n}$
In questo caso l'OS deve adeguarsi al hardware cui e' posto, cosi' facendo la sequenza lineare di valori degli indirizzi fisici e' interpretata come coppia di valori
- bit piu' significativi come numero del frame
- bit meno significativi come offset $d$
Questo e' implementato in modo piu' semplice utilizzando come grandezze di indirizzamento potenze di 2
- in questo modo:
  + non sara' necessario memorizzare l'indirizzo di partenza del _frame_ ma solo il suo _numero_
  + non sara' necessario operare una somma tra indirizzo e offset ma solamente una _concatenazione_ (piu' veloce)
**** Paginazione a piu' livelli

** Virtuale

* Gestione Memoria di massa

** Rigidi

** RAID

** File System

*** Interfaccia

*** Realizzazione
* Laboratorio

** [[file:20200929150429-c.org][C]]

** [[file:20200929150510-unix.org][Unix]]
